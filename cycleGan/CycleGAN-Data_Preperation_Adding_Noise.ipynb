{"cells":[{"cell_type":"markdown","metadata":{"id":"GctOb3cgCSm-"},"source":["# Code for generating noisy signature images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ts4FpCE_CSm_"},"outputs":[],"source":["def add_random_straight_lines(image,height, width):\n","    ''' Add random straight lines to the image '''\n","    num_lines = np.random.randint(1, 5) # number of lines to be added\n","    y0 = int(height/num_lines) # gap/width between each lines\n","    for i in range(num_lines):\n","        line_thickness = np.random.randint(1, 5)\n","        x1, x2 = 0, width # starting and ending x coordinates\n","        y = y0*(i+1) + np.random.randint(-0.05*height, 0.05*height) # y coordinate of line\n","        image = cv2.line(image, (x1, y), (x2, y), (0, 0, 0), thickness=line_thickness) #draw line\n","        prev_y = y\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8npmM--0CSnB"},"outputs":[],"source":["def add_random_text(image, height, width):\n","    ''' Add random texts to the image '''\n","    closings = ['Sincerly', 'Regards', 'Yours truly', 'Best regards', 'Cordially']\n","    bottom_text = ['Amal Joseph', 'Steve Jobs', 'Larry Page', 'Paul Walker', 'Raja Ravi Varma', 'Katie Bouman', 'Ada Loveless']\n","\n","    font = [cv2.FONT_HERSHEY_DUPLEX, cv2.FONT_HERSHEY_COMPLEX, cv2.FONT_HERSHEY_TRIPLEX, cv2.FONT_HERSHEY_COMPLEX_SMALL]\n","    y = np.random.randint(0.75*height, 1.02*height)\n","    x = np.random.randint(0.0005*width, 0.3*width)\n","    fontScale = np.random.random() + 0.7\n","    thickness = np.random.randint(1, 3)\n","    image = cv2.putText(image, np.random.choice(bottom_text), (x, y), np.random.choice(font), fontScale, (0, 0, 0), thickness, cv2.LINE_AA)\n","    return image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWxrv0PACSnC"},"outputs":[],"source":["def process_image(image_path):    \n","    ''' Add random straight lines and texts to the image '''\n","    image = cv2.imread(image_path)\n","    height, weight, _ = image.shape\n","    image = add_random_text(image, height, width)\n","    image = add_random_straight_lines(image, height, width)\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ovkAeu7jCSnD"},"outputs":[],"source":["# usage example\n","image = cv2.imread(imagepath)\n","height, width, _ = image.shape\n","image = process_image(image, height, width)\n","plt.imshow(image)"]},{"cell_type":"markdown","metadata":{"id":"EpEB3WjUCSnE"},"source":["# Convert Dataset to CycleGAN Folder Structure  \n","CycleGAN perform image (domainA) to image (domainB) translation. Train and test images of domainA (clean signatures) must be stored in folders trainA and testA respectively. Similarily, the images in domainB (noisy) should be stored in trainB and testB  \n","  \n","Note: I moved all the signatures (from all the subfolders in train and test directory) in Kaggle dataset into one single directory, and the following operations are performed on the resultant folder which contains all the signatures.  \n","Used only the real signatures from the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"plHb744ZCSnF"},"outputs":[],"source":["# move images from sub directories to another folder\n","root_path = 'gan_signdata_kaggle/images/'\n","\n","for root, dirs, files in os.walk(root_path):\n","    for filename in files:\n","        shutil.move(os.path.join(root, filename), 'gan-sign_data_kaggle/A/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V1Qno77XCSnG"},"outputs":[],"source":["# apply image augumentations and save them\n","root_path = 'gan-sign_data_kaggle/images/'\n","for root, dirs, files in os.walk(root_path):\n","    for filename in files:\n","        image = process_image(os.path.join(root, filename))\n","        cv2.imwrite(f'gan-sign_data_kaggle/B/{filename}', image)\n","#         shutil.move(os.path.join(root, filename), 'gan-sign_data_kaggle/images/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZubMDw_OCSnH"},"outputs":[],"source":["# splitting into train and test\n","root = 'gan_signdata_kaggle/'\n","srcA_path = 'gan_signdata_kaggle/A/'\n","srcB_path = 'gan_signdata_kaggle/B/'\n","\n","trainA_path = 'gan_signdata_kaggle (copy)/trainA/'\n","testA_path = 'gan_signdata_kaggle (copy)/testA/'\n","\n","\n","trainB_path = 'gan_signdata_kaggle (copy)/trainB/'\n","testB_path = 'gan_signdata_kaggle (copy)/testB/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"83TqY1FwCSnI"},"outputs":[],"source":["def split_data(src_path, train_path, test_path, split_ratio):\n","    files = np.array(os.listdir(src_path))\n","    np.random.shuffle(files)\n","    split_index = int(split_ratio * len(files))\n","    testA = files[0:split_index]\n","    trainA = files[split_index:]\n","    [shutil.move(os.path.join(src_path, path), os.path.join(train_path, path)) for path in trainA]\n","    [shutil.move(os.path.join(src_path, path), os.path.join(test_path, path)) for path in testA]\n","\n","split_data(srcA_path, trainA_path, testA_path, 0.1)\n","split_data(srcB_path, trainB_path, testB_path, 0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8jVjSMYTCSnI"},"outputs":[],"source":["os.rmdir(srcA_path)\n","os.rmdir(srcB_path)\n","os.rmdir('gan-sign_data_kaggle/images/')"]},{"cell_type":"markdown","metadata":{"id":"mSurMU-xCSnI"},"source":["# Transforming images to CycleGAN input format\n","CycleGAN requires images of same shape, so I decided to train it with 512x512 images with signature at the center and black (transparent) strips at top and bottom."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBR1u7MRCSnJ"},"outputs":[],"source":["# to find the maximum width and height present in the images\n","from PIL import Image\n","import os, sys\n","size_images = dict()\n","\n","for dirpath, _, filenames in os.walk(trainA_path):\n","    for path_image in filenames:\n","        image = os.path.abspath(os.path.join(dirpath, path_image))\n","        with Image.open(image) as img:\n","            width, heigth = img.size\n","            SIZE_IMAGES[path_image] = {'width': width, 'heigth': heigth}\n","print(size_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3NExrm42CSnJ"},"outputs":[],"source":["import os\n","from PIL import Image\n","im_size = 512\n","def make_square(image, min_size=512, fill_color=(255, 255, 255, 0)):\n","    ''' Resize image as a square with signature in the center and black(transparent) strips at top and bottom. '''\n","    x, y = image.size\n","    size = max(min_size, x, y)\n","    new_im = Image.new('RGBA', (size, size), fill_color)\n","    new_im.paste(image, (int((size - x) / 2), int((size - y) / 2)))\n","    new_im = new_im.resize((im_size, im_size))\n","    return new_im\n","\n","def resize_images(path):\n","    ''' Function to resize the images to the ip format for gans. '''\n","    dirs = os.listdir(path)\n","    for item in dirs:\n","        if os.path.isfile(path+item):\n","            image = Image.open(path+item)\n","            image = make_square(image)\n","            image.save(path+item)\n","\n","resize_images(trainA_path)\n","resize_images(trainB_path)\n","resize_images(testA_path)\n","resize_images(testB_path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}